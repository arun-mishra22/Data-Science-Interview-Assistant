{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1373027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpaca \n",
    "# OpenAssistant \n",
    "# kaggle \n",
    "# Synthetic "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb381e5",
   "metadata": {},
   "source": [
    "#### Loading dataset From alpaca -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969c403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/arun4/.cache/huggingface/datasets/tatsu-lab___parquet/tatsu-lab--alpaca-2b32f0433506ef5f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e5a55b691f4e9abc43418281f2a439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'input', 'output', 'text'],\n",
      "        num_rows: 52002\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"tatsu-lab/alpaca\")\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5c471e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Give three tips for staying healthy.', 'input': '', 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2caba818",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    \"data science\",\n",
    "    \"machine learning\",\n",
    "    \"deep learning\",\n",
    "    \"artificial intelligence\",\n",
    "    \"neural network\",\n",
    "    \"statistics\",\n",
    "    \"probability\",\n",
    "    \"python\",\n",
    "    \"pandas\",\n",
    "    \"numpy\",\n",
    "    \"sql\",\n",
    "    \"nlp\",\n",
    "    \"computer vision\",\n",
    "    \"regression\",\n",
    "    \"classification\",\n",
    "    \"clustering\",\n",
    "    \"model\",\n",
    "    \"overfitting\",\n",
    "    \"underfitting\",\n",
    "    \"gradient descent\",\n",
    "    \"interview\",\n",
    "    \"data analysis\",\n",
    "    \"feature engineering\",\n",
    "    \"data preprocessing\",\n",
    "    \"data visualization\",\n",
    "    \"decision tree\",\n",
    "    \"random forest\",\n",
    "    \"xgboost\",\n",
    "    \"transformer\",\n",
    "    \"llm\",\n",
    "    \"mlops\",\n",
    "    \"hyperparameter\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f337dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ds_related(example):\n",
    "    instruction = example[\"instruction\"].lower()\n",
    "    \n",
    "    return any(keyword in instruction for keyword in keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33219de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arun4\\.cache\\huggingface\\datasets\\tatsu-lab___parquet\\tatsu-lab--alpaca-2b32f0433506ef5f\\0.0.0\\2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-0e70526648b7e046.arrow\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset[\"train\"]\n",
    "\n",
    "filtered_data = train_data.filter(filter_ds_related)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41d37887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 52002\n",
      "Filtered size: 2226\n"
     ]
    }
   ],
   "source": [
    "print(\"Original size:\", len(train_data))\n",
    "print(\"Filtered size:\", len(filtered_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35bbdb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'text'],\n",
       "    num_rows: 2226\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93780007",
   "metadata": {},
   "source": [
    "##### cleaning the filtered data set  -->\n",
    "Remove noisy records\n",
    "\n",
    "Fix formatting issues\n",
    "\n",
    "Remove very short/very long samples\n",
    "\n",
    "Remove bad quality answers\n",
    "\n",
    "Standardize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d08b8eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def basic_clean(example):\n",
    "    def clean_text(text):\n",
    "        text = text.strip()\n",
    "        text = re.sub(r\"\\s+\", \" \", text)   # remove extra spaces\n",
    "        return text\n",
    "\n",
    "    return {\n",
    "        \"instruction\": clean_text(example[\"instruction\"]),\n",
    "        \"input\": clean_text(example[\"input\"]) if example[\"input\"] else \"\",\n",
    "        \"output\": clean_text(example[\"output\"])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0198349e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arun4\\.cache\\huggingface\\datasets\\tatsu-lab___parquet\\tatsu-lab--alpaca-2b32f0433506ef5f\\0.0.0\\2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-e130327abbd68cd9.arrow\n"
     ]
    }
   ],
   "source": [
    "cleaned = filtered_data.map(basic_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4afcf38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arun4\\.cache\\huggingface\\datasets\\tatsu-lab___parquet\\tatsu-lab--alpaca-2b32f0433506ef5f\\0.0.0\\2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-f31d3a7510bbaca9.arrow\n"
     ]
    }
   ],
   "source": [
    "## Remove Low Quality Records\n",
    "\n",
    "def remove_empty(example):\n",
    "    return len(example[\"instruction\"]) > 10 and len(example[\"output\"]) > 10\n",
    "\n",
    "cleaned = cleaned.filter(remove_empty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b6b4293",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Very Short or Very Long Samples\n",
    "\n",
    "def length_filter(example):\n",
    "    total_len = len(example[\"instruction\"]) + len(example[\"output\"])\n",
    "    return 30 < total_len < 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ae70be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arun4\\.cache\\huggingface\\datasets\\tatsu-lab___parquet\\tatsu-lab--alpaca-2b32f0433506ef5f\\0.0.0\\2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-fed9665589cf2b00.arrow\n"
     ]
    }
   ],
   "source": [
    "cleaned = cleaned.filter(length_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4af32ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After deduplication: 2190\n"
     ]
    }
   ],
   "source": [
    "## Remove Duplicates\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Convert to pandas\n",
    "df = cleaned.to_pandas()\n",
    "\n",
    "# Remove duplicate rows based on instruction + output\n",
    "df = df.drop_duplicates(subset=[\"instruction\", \"output\"])\n",
    "\n",
    "# Convert back to HuggingFace dataset\n",
    "cleaned_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "print(\"After deduplication:\", len(cleaned_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2616b8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230113e497ff4468824b3cf1bb6f5105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Create Final Prompt Format\n",
    "\n",
    "def create_prompt(example):\n",
    "    if example[\"input\"]:\n",
    "        text = f\"\"\"### Instruction:\n",
    "{example[\"instruction\"]}\n",
    "\n",
    "### Input:\n",
    "{example[\"input\"]}\n",
    "\n",
    "### Response:\n",
    "{example[\"output\"]}\"\"\"\n",
    "    else:\n",
    "        text = f\"\"\"### Instruction:\n",
    "{example[\"instruction\"]}\n",
    "\n",
    "### Response:\n",
    "{example[\"output\"]}\"\"\"\n",
    "\n",
    "    return {\"text\": text}\n",
    "\n",
    "final_cleaned = cleaned_dataset.map(create_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05979378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cleaned size: 2190\n",
      "{'instruction': 'Render a 3D model of a house', 'input': '', 'output': '<nooutput> This type of instruction cannot be fulfilled by a GPT model.', 'text': '### Instruction:\\nRender a 3D model of a house\\n\\n### Response:\\n<nooutput> This type of instruction cannot be fulfilled by a GPT model.'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final cleaned size:\", len(final_cleaned))\n",
    "print(final_cleaned[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1749dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Non-Textual / Non-Answerable Tasks\n",
    "\n",
    "bad_keywords = [\n",
    "    \"render\",\n",
    "    \"draw\",\n",
    "    \"paint\",\n",
    "    \"image of\",\n",
    "    \"picture of\",\n",
    "    \"3d model\",\n",
    "    \"generate an image\",\n",
    "    \"create a video\",\n",
    "    \"audio file\",\n",
    "    \"physical\",\n",
    "    \"real world action\"\n",
    "]\n",
    "\n",
    "def remove_bad_tasks(example):\n",
    "    text = example[\"instruction\"].lower()\n",
    "    return not any(k in text for k in bad_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3d81e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee8007aff1b47629bf7d1ce3256d78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing non-text tasks: 2179\n"
     ]
    }
   ],
   "source": [
    "cleaned = final_cleaned.filter(remove_bad_tasks)\n",
    "\n",
    "print(\"After removing non-text tasks:\", len(cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "150d2d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cba93da8b7449295f98dd95266b8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2179 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleaned.save_to_disk(\"alpaca_ds_cleaned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a486b5b",
   "metadata": {},
   "source": [
    "Loading open-assistant dataset -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a51a219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/arun4/.cache/huggingface/datasets/OpenAssistant___parquet/OpenAssistant--oasst1-2960c57d7e52ab15/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23dc779f0ee45ffa273729667a11e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['message_id', 'parent_id', 'user_id', 'created_date', 'text', 'role', 'lang', 'review_count', 'review_result', 'deleted', 'rank', 'synthetic', 'model_name', 'detoxify', 'message_tree_id', 'tree_state', 'emojis', 'labels'],\n",
      "        num_rows: 84437\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['message_id', 'parent_id', 'user_id', 'created_date', 'text', 'role', 'lang', 'review_count', 'review_result', 'deleted', 'rank', 'synthetic', 'model_name', 'detoxify', 'message_tree_id', 'tree_state', 'emojis', 'labels'],\n",
      "        num_rows: 4401\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load OpenAssistant dataset\n",
    "dataset = load_dataset(\"OpenAssistant/oasst1\")\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213afc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message_id': '6ab24d72-0181-4594-a9cd-deaf170242fb', 'parent_id': None, 'user_id': 'c3fe8c76-fc30-4fa7-b7f8-c492f5967d18', 'created_date': '2023-02-05T14:23:50.983374+00:00', 'text': 'Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.', 'role': 'prompter', 'lang': 'en', 'review_count': 3, 'review_result': True, 'deleted': False, 'rank': None, 'synthetic': False, 'model_name': None, 'detoxify': {'toxicity': 0.00044308538781479, 'severe_toxicity': 3.252684837207198e-05, 'obscene': 0.00023475120542570949, 'identity_attack': 0.0001416115992469713, 'insult': 0.00039489680784754455, 'threat': 4.075629112776369e-05, 'sexual_explicit': 2.712695459194947e-05}, 'message_tree_id': '6ab24d72-0181-4594-a9cd-deaf170242fb', 'tree_state': 'ready_for_export', 'emojis': {'name': ['+1', '_skip_reply', '_skip_ranking'], 'count': [10, 1, 4]}, 'labels': {'name': ['spam', 'lang_mismatch', 'pii', 'not_appropriate', 'hate_speech', 'sexual_content', 'quality', 'toxicity', 'humor', 'creativity', 'violence'], 'value': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9166666666666666, 0.16666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0], 'count': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]}}\n",
      "{'message_id': 'c8e83833-ecbc-44fe-b6db-735228c25a1c', 'parent_id': '6ab24d72-0181-4594-a9cd-deaf170242fb', 'user_id': '2c96e467-66f0-4be7-9693-bda51356a424', 'created_date': '2023-02-06T13:50:44.657083+00:00', 'text': '\"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.', 'role': 'assistant', 'lang': 'en', 'review_count': 3, 'review_result': True, 'deleted': False, 'rank': 0, 'synthetic': False, 'model_name': None, 'detoxify': {'toxicity': 0.00026396565954200923, 'severe_toxicity': 2.7454958399175666e-05, 'obscene': 0.00013584605767391622, 'identity_attack': 9.263094398193061e-05, 'insult': 0.0001668655313551426, 'threat': 3.769186878344044e-05, 'sexual_explicit': 2.500762275303714e-05}, 'message_tree_id': '6ab24d72-0181-4594-a9cd-deaf170242fb', 'tree_state': 'ready_for_export', 'emojis': {'name': ['+1', '_skip_labeling'], 'count': [3, 1]}, 'labels': {'name': ['spam', 'fails_task', 'lang_mismatch', 'pii', 'not_appropriate', 'hate_speech', 'sexual_content', 'quality', 'toxicity', 'humor', 'helpfulness', 'creativity', 'violence'], 'value': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9166666666666666, 0.375, 0.375, 0.75, 0.375, 0.0], 'count': [3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2]}}\n",
      "{'message_id': '6708c47f-05c9-4346-b3d2-40b2bd24fde4', 'parent_id': 'c8e83833-ecbc-44fe-b6db-735228c25a1c', 'user_id': '2c96e467-66f0-4be7-9693-bda51356a424', 'created_date': '2023-02-06T18:48:49.391686+00:00', 'text': 'Now explain it to a dog', 'role': 'prompter', 'lang': 'en', 'review_count': 3, 'review_result': True, 'deleted': False, 'rank': None, 'synthetic': False, 'model_name': None, 'detoxify': {'toxicity': 0.03648477792739868, 'severe_toxicity': 5.486844383995049e-05, 'obscene': 0.0003762090636882931, 'identity_attack': 0.0002415566414128989, 'insult': 0.013612336479127407, 'threat': 0.0017075861105695367, 'sexual_explicit': 0.00010235361696686596}, 'message_tree_id': '6ab24d72-0181-4594-a9cd-deaf170242fb', 'tree_state': 'ready_for_export', 'emojis': None, 'labels': {'name': ['spam', 'lang_mismatch', 'pii', 'not_appropriate', 'hate_speech', 'sexual_content', 'quality', 'toxicity', 'humor', 'creativity', 'violence'], 'value': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.5, 0.625, 0.5, 0.0], 'count': [3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2]}}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0])\n",
    "print(dataset[\"train\"][1])\n",
    "print(dataset[\"train\"][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32bd924b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompter', 'assistant'}\n"
     ]
    }
   ],
   "source": [
    "roles = set(dataset[\"train\"][\"role\"])\n",
    "print(roles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a7b55a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 prompter\n",
      "1 assistant\n",
      "2 prompter\n",
      "3 assistant\n",
      "4 prompter\n",
      "5 assistant\n",
      "6 prompter\n",
      "7 assistant\n",
      "8 assistant\n",
      "9 assistant\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, dataset[\"train\"][i][\"role\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfd55a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[\"train\"]  \n",
    "alpaca_style = []\n",
    "\n",
    "for i in range(len(data) - 1):\n",
    "    current = data[i]\n",
    "    next_msg = data[i + 1]\n",
    "\n",
    "    # Only take valid prompter â†’ assistant pairs\n",
    "    if current[\"role\"] == \"prompter\" and next_msg[\"role\"] == \"assistant\":\n",
    "        alpaca_style.append({\n",
    "            \"instruction\": current[\"text\"].strip(),\n",
    "            \"input\": \"\",\n",
    "            \"output\": next_msg[\"text\"].strip()\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "372e1f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output'],\n",
      "    num_rows: 27904\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# convert to hugging face dataset \n",
    "from datasets import Dataset\n",
    "\n",
    "oa_dataset = Dataset.from_list(alpaca_style)\n",
    "\n",
    "print(oa_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db3584f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    \"data science\",\n",
    "    \"machine learning\",\n",
    "    \"deep learning\",\n",
    "    \"artificial intelligence\",\n",
    "    \"neural network\",\n",
    "    \"statistics\",\n",
    "    \"probability\",\n",
    "    \"python\",\n",
    "    \"pandas\",\n",
    "    \"numpy\",\n",
    "    \"sql\",\n",
    "    \"nlp\",\n",
    "    \"computer vision\",\n",
    "    \"regression\",\n",
    "    \"classification\",\n",
    "    \"clustering\",\n",
    "    \"model\",\n",
    "    \"overfitting\",\n",
    "    \"underfitting\",\n",
    "    \"gradient descent\",\n",
    "    \"interview\",\n",
    "    \"data analysis\",\n",
    "    \"feature engineering\",\n",
    "    \"data preprocessing\",\n",
    "    \"data visualization\",\n",
    "    \"decision tree\",\n",
    "    \"random forest\",\n",
    "    \"xgboost\",\n",
    "    \"transformer\",\n",
    "    \"llm\",\n",
    "    \"mlops\",\n",
    "    \"hyperparameter\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d7a3ec",
   "metadata": {},
   "source": [
    "filtering rows for data science domain \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4598ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f8c6889e114b99805749a0bedc7f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/27904 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after DS filtering: 1165\n"
     ]
    }
   ],
   "source": [
    "def filter_ds_related(example):\n",
    "    text = example[\"instruction\"].lower()\n",
    "    return any(keyword in text for keyword in keywords)\n",
    "\n",
    "oa_filtered = oa_dataset.filter(filter_ds_related)\n",
    "\n",
    "print(\"Rows after DS filtering:\", len(oa_filtered))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b00549f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7adb921e3afb4f39a8ae3144056b800c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1165 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## basic cleaning - remove extra space and normalize text \n",
    "\n",
    "import re\n",
    "\n",
    "def basic_clean(example):\n",
    "    def normalize(text):\n",
    "        text = text.strip()\n",
    "        text = re.sub(r\"\\s+\", \" \", text)   # remove multiple spaces\n",
    "        return text\n",
    "\n",
    "    return {\n",
    "        \"instruction\": normalize(example[\"instruction\"]),\n",
    "        \"input\": \"\",\n",
    "        \"output\": normalize(example[\"output\"])\n",
    "    }\n",
    "\n",
    "oa_cleaned = oa_filtered.map(basic_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33215822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c35d8f99314ff6a78ab46fc527b16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1165 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After length filtering: 1139\n"
     ]
    }
   ],
   "source": [
    "## remove very short or use less rows\n",
    "\n",
    "def length_filter(example):\n",
    "    return len(example[\"instruction\"]) > 15 and len(example[\"output\"]) > 30\n",
    "\n",
    "oa_cleaned = oa_cleaned.filter(length_filter)\n",
    "\n",
    "print(\"After length filtering:\", len(oa_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82834982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d166618918ef46aa8fc1daf3d85dcd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After noise removal: 1108\n"
     ]
    }
   ],
   "source": [
    "## remove Non- Interview Style Content \n",
    "\n",
    "bad_patterns = [\"joke\", \"story\", \"poem\", \"translate\", \"email\", \"lyrics\"]\n",
    "\n",
    "def remove_noise(example):\n",
    "    text = example[\"instruction\"].lower()\n",
    "    return not any(p in text for p in bad_patterns)\n",
    "\n",
    "oa_cleaned = oa_cleaned.filter(remove_noise)\n",
    "\n",
    "print(\"After noise removal:\", len(oa_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9da602bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee58aa8882c4d29ad19b02e068bfad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Create Final training prompt feild \n",
    "\n",
    "def create_prompt(example):\n",
    "    text = f\"\"\"### Instruction:\n",
    "{example['instruction']}\n",
    "\n",
    "### Response:\n",
    "{example['output']}\"\"\"\n",
    "    return {\"text\": text}\n",
    "\n",
    "oa_final = oa_cleaned.map(create_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d0bcac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cleaned OpenAssistant rows: 1108\n",
      "{'instruction': 'Can you explain contrastive learning in machine learning in simple terms for someone new to the field of ML?', 'input': '', 'output': 'Sure! Let\\'s say you want to build a model which can distinguish between images of cats and dogs. You gather your dataset, consisting of many cat and dog pictures. Then you put them through a neural net of your choice, which produces some representation for each image, a sequence of numbers like [0.123, 0.045, 0.334, ...]. The problem is, if your model is unfamiliar with cat and dog images, these representations will be quite random. At one time a cat and a dog picture could have very similar representations (their numbers would be close to each other), while at others two cat images may be represented far apart. In simple terms, the model wouldn\\'t be able to tell cats and dogs apart. This is where contrastive learning comes in. The point of contrastive learning is to take pairs of samples (in this case images of cats and dogs), then train the model to \"pull\" representations of similar pairs (cat-cat or dog-dog) closer to each other and \"push\" representations of different pairs (cat-dog) apart. After doing this for a sufficient number of steps, your model will be able to produce unique, reliable representations for cats and dogs, in essence tell them apart. This method is not limited to images, you can typically use it with any dataset that has similar and dissimilar data points.', 'text': '### Instruction:\\nCan you explain contrastive learning in machine learning in simple terms for someone new to the field of ML?\\n\\n### Response:\\nSure! Let\\'s say you want to build a model which can distinguish between images of cats and dogs. You gather your dataset, consisting of many cat and dog pictures. Then you put them through a neural net of your choice, which produces some representation for each image, a sequence of numbers like [0.123, 0.045, 0.334, ...]. The problem is, if your model is unfamiliar with cat and dog images, these representations will be quite random. At one time a cat and a dog picture could have very similar representations (their numbers would be close to each other), while at others two cat images may be represented far apart. In simple terms, the model wouldn\\'t be able to tell cats and dogs apart. This is where contrastive learning comes in. The point of contrastive learning is to take pairs of samples (in this case images of cats and dogs), then train the model to \"pull\" representations of similar pairs (cat-cat or dog-dog) closer to each other and \"push\" representations of different pairs (cat-dog) apart. After doing this for a sufficient number of steps, your model will be able to produce unique, reliable representations for cats and dogs, in essence tell them apart. This method is not limited to images, you can typically use it with any dataset that has similar and dissimilar data points.'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final cleaned OpenAssistant rows:\", len(oa_final))\n",
    "print(oa_final[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60fe07d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a88412edb8d4e98b5fe3de19ef8e199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## saving the cleaned dataset \n",
    "oa_final.save_to_disk(\"openassistant_ds_cleaned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db537944",
   "metadata": {},
   "source": [
    "Loading Kaggle ml_interview_questions -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227b0455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/arun4/.cache/huggingface/datasets/csv/default-3bc42a4a125c2dfc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a380bd03da4d0b8185b3773468baf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6ba2fac21d4e078ae3e789ad73ac30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d2f71f51a34ce99d81bc8726740609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/arun4/.cache/huggingface/datasets/csv/default-3bc42a4a125c2dfc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0164b34bacb94ec68e01a90e7c361e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'question', 'answer', 'category', 'difficulty', 'company_tags', 'topic_tags', 'answer_length'],\n",
      "    num_rows: 502\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=\"ml_interview_questions.csv\")\n",
    "\n",
    "data = dataset[\"train\"]\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conversion funtion - to convert in alpaca format \n",
    "\n",
    "def convert_to_alpaca(example):\n",
    "    return {\n",
    "        \"instruction\": example[\"question\"].strip(),\n",
    "        \"input\": \"\",\n",
    "        \"output\": example[\"answer\"].strip()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "852eec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\arun4\\.cache\\huggingface\\datasets\\csv\\default-3bc42a4a125c2dfc\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-5594d89436c359b2.arrow\n"
     ]
    }
   ],
   "source": [
    "kaggle_ds = data.map(\n",
    "    convert_to_alpaca,\n",
    "    remove_columns=data.column_names\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd28c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaee0b6d6f10407b9ed8e447a3b5333f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/502 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the Text Prompt Field\n",
    "def create_prompt(example):\n",
    "    text = f\"\"\"### Instruction:\n",
    "{example[\"instruction\"]}\n",
    "\n",
    "### Response:\n",
    "{example[\"output\"]}\"\"\"\n",
    "    return {\"text\": text}\n",
    "\n",
    "kaggle_ds = kaggle_ds.map(create_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214deaf",
   "metadata": {},
   "source": [
    "Basic cleaning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9fb6b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e05e410f5d484ca28f46a42c01a455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/502 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Remove very small rows\n",
    "\n",
    "def quality_filter(example):\n",
    "    return len(example[\"instruction\"]) > 10 and len(example[\"output\"]) > 20\n",
    "\n",
    "kaggle_ds = kaggle_ds.filter(quality_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a04cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Describe the ConvNeXt architecture and its key innovations.', 'input': '', 'output': 'ConvNeXt is a notable deep learning architecture with important innovations. It addresses limitations of prior approaches and has been widely adopted. Key choices include its feature extraction approach, computational efficiency, and scalability. Understanding it is valuable for state-of-the-art systems.', 'text': '### Instruction:\\nDescribe the ConvNeXt architecture and its key innovations.\\n\\n### Response:\\nConvNeXt is a notable deep learning architecture with important innovations. It addresses limitations of prior approaches and has been widely adopted. Key choices include its feature extraction approach, computational efficiency, and scalability. Understanding it is valuable for state-of-the-art systems.'}\n",
      "{'instruction': 'What is data augmentation and why is it important for computer vision?', 'input': '', 'output': 'Data augmentation applies random transformations to training images (rotation, flipping, cropping, color jittering, scaling) to increase effective training set size and improve generalization. It reduces overfitting and makes models invariant to transformations. Advanced: CutOut, CutMix, MixUp, AutoAugment, RandAugment. For certain tasks like medical imaging, augmentation is critical due to limited labeled data. Test-time augmentation (TTA) averages predictions across augmented copies at inference.', 'text': '### Instruction:\\nWhat is data augmentation and why is it important for computer vision?\\n\\n### Response:\\nData augmentation applies random transformations to training images (rotation, flipping, cropping, color jittering, scaling) to increase effective training set size and improve generalization. It reduces overfitting and makes models invariant to transformations. Advanced: CutOut, CutMix, MixUp, AutoAugment, RandAugment. For certain tasks like medical imaging, augmentation is critical due to limited labeled data. Test-time augmentation (TTA) averages predictions across augmented copies at inference.'}\n"
     ]
    }
   ],
   "source": [
    "print(kaggle_ds[0])\n",
    "print(kaggle_ds[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45a24a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\n"
     ]
    }
   ],
   "source": [
    "print(len(kaggle_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68a63c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686e13ed821d45d68d31d9e0fcb84d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/502 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kaggle_ds.save_to_disk(\"kaggle_interview_cleaned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfb264e",
   "metadata": {},
   "source": [
    "Loading some synthetic data -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2718ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 shape: (500, 3)\n",
      "Dataset 2 shape: (500, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load synthetic datasets\n",
    "ds1 = pd.read_csv(\"ds_instruction_dataset_1.csv\")\n",
    "ds2 = pd.read_csv(\"ds_instruction_dataset_2.csv\")\n",
    "\n",
    "print(\"Dataset 1 shape:\", ds1.shape)\n",
    "print(\"Dataset 2 shape:\", ds2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91dd3325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['instruction', 'input', 'output'], dtype='object')\n",
      "Index(['instruction', 'input', 'output'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ds1.columns)\n",
    "print(ds2.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2fd3c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total synthetic rows: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "## combining both datasets \n",
    "synthetic = pd.concat([ds1, ds2], ignore_index=True)\n",
    "\n",
    "print(\"Total synthetic rows:\", synthetic.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating Prompt Template\n",
    "\n",
    "def create_prompt(row):\n",
    "    return f\"\"\"### Instruction:\n",
    "{row['instruction']}\n",
    "\n",
    "### Question:\n",
    "{row['input']}\n",
    "\n",
    "### Answer:\n",
    "{row['output']}\n",
    "\"\"\"\n",
    "\n",
    "synthetic[\"text\"] = synthetic.apply(create_prompt, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bddeda93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does neural networks help in data science ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neural networks helps by improving accuracy, e...</td>\n",
       "      <td>### Instruction:\\nHow does neural networks hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explain the concept of MLOps.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The concept of MLOps refers to fundamental pri...</td>\n",
       "      <td>### Instruction:\\nExplain the concept of MLOps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is algorithms and why is it important?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>algorithms is a key area in data science. It h...</td>\n",
       "      <td>### Instruction:\\nWhat is algorithms and why i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What mistakes should be avoided in MLOps?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Common mistakes in MLOps include poor understa...</td>\n",
       "      <td>### Instruction:\\nWhat mistakes should be avoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explain python in beginner friendly language.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>python can be understood as a way to analyze a...</td>\n",
       "      <td>### Instruction:\\nExplain python in beginner f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  input  \\\n",
       "0  How does neural networks help in data science ...    NaN   \n",
       "1                      Explain the concept of MLOps.    NaN   \n",
       "2        What is algorithms and why is it important?    NaN   \n",
       "3          What mistakes should be avoided in MLOps?    NaN   \n",
       "4      Explain python in beginner friendly language.    NaN   \n",
       "\n",
       "                                              output  \\\n",
       "0  neural networks helps by improving accuracy, e...   \n",
       "1  The concept of MLOps refers to fundamental pri...   \n",
       "2  algorithms is a key area in data science. It h...   \n",
       "3  Common mistakes in MLOps include poor understa...   \n",
       "4  python can be understood as a way to analyze a...   \n",
       "\n",
       "                                                text  \n",
       "0  ### Instruction:\\nHow does neural networks hel...  \n",
       "1  ### Instruction:\\nExplain the concept of MLOps...  \n",
       "2  ### Instruction:\\nWhat is algorithms and why i...  \n",
       "3  ### Instruction:\\nWhat mistakes should be avoi...  \n",
       "4  ### Instruction:\\nExplain python in beginner f...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f5c97f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfd5f6b25d44d4aa3fc33073e574223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##  synthetic is currently a pandas DataFrame, not a Hugging Face Dataset.\n",
    "##  coverting pandas dataframe into huggingface dataset \n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "synthetic_ds = Dataset.from_pandas(synthetic)\n",
    "\n",
    "synthetic_ds.save_to_disk(\"synthetic_ds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216e4bed",
   "metadata": {},
   "source": [
    "Loading all datasets -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5cff3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpaca: Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'text'],\n",
      "    num_rows: 2179\n",
      "})\n",
      "OpenAssistant: Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'text'],\n",
      "    num_rows: 1108\n",
      "})\n",
      "Kaggle: Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'text'],\n",
      "    num_rows: 502\n",
      "})\n",
      "Synthetic: Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'text'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk, concatenate_datasets\n",
    "\n",
    "alpaca = load_from_disk(\"alpaca_ds_cleaned\")\n",
    "oasst = load_from_disk(\"openassistant_ds_cleaned\")\n",
    "kaggle = load_from_disk(\"kaggle_interview_cleaned\")\n",
    "synthetic = load_from_disk(\"synthetic_ds\")\n",
    "\n",
    "print(\"Alpaca:\", alpaca)\n",
    "print(\"OpenAssistant:\", oasst)\n",
    "print(\"Kaggle:\", kaggle)\n",
    "print(\"Synthetic:\", synthetic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5193e8",
   "metadata": {},
   "source": [
    "Before concatenating, we must standardize all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e115ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function \n",
    "def fix_types(dataset):\n",
    "    return dataset.map(lambda x: {\n",
    "        \"instruction\": str(x[\"instruction\"]),\n",
    "        \"input\": str(x[\"input\"]),\n",
    "        \"output\": str(x[\"output\"]),\n",
    "        \"text\": str(x[\"text\"])\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d7cd117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97450c19875a443fa7fa5cc9bd46f918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2179 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724b545f24b64797ba333e3ebd2161c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b152238c1254732a596bfe076fb9572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/502 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b913256934f40feabe516736da8bba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpaca = fix_types(alpaca)\n",
    "oasst = fix_types(oasst)\n",
    "kaggle = fix_types(kaggle)\n",
    "synthetic = fix_types(synthetic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e682cce4",
   "metadata": {},
   "source": [
    "Concatinating the datasets -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29aca76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size: Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'text'],\n",
      "    num_rows: 4789\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "final_dataset = concatenate_datasets([alpaca, oasst, kaggle, synthetic])\n",
    "\n",
    "print(\"Final dataset size:\", final_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29243199",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle the dataset \n",
    "\n",
    "final_dataset = final_dataset.shuffle(seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2fa7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'text'],\n",
      "    num_rows: 4310\n",
      "})\n",
      "Test size: Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'text'],\n",
      "    num_rows: 479\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "## Create Train / Test Split\n",
    "\n",
    "\n",
    "split = final_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "train_dataset = split[\"train\"]\n",
    "test_dataset = split[\"test\"]\n",
    "\n",
    "print(\"Train size:\", train_dataset)\n",
    "print(\"Test size:\", test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d05dc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instruction', 'input', 'output', 'text']\n",
      "['instruction', 'input', 'output', 'text']\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.column_names)\n",
    "print(test_dataset.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9beedc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing the Unnecessary columns \n",
    "\n",
    "train_dataset = train_dataset.remove_columns([\"instruction\", \"input\", \"output\"])\n",
    "test_dataset = test_dataset.remove_columns([\"instruction\", \"input\", \"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "730e4abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text']\n",
      "['text']\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.column_names)\n",
    "print(test_dataset.column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abcf857",
   "metadata": {},
   "source": [
    "The final train and test datasets are loaded .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b563e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9141b2e36634e0d86066fb90a65c47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001a4c7719ec408f8e63d0abb6a09651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/479 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset.save_to_disk(\"train_dataset\")\n",
    "test_dataset.save_to_disk(\"test_dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2598c2e",
   "metadata": {},
   "source": [
    "Fine tuning preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f18d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading final dataset \n",
    "from datasets import load_from_disk\n",
    "\n",
    "train_data = load_from_disk(\"train_dataset\")\n",
    "val_data = load_from_disk(\"test_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c7bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LLama model -- meta-llama/Llama-3.2-3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa7d5517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/6f/3d/c87b33c5f260a2a8ad68da7147e105f05868c281c63d65ed85aa4da98c66/torch-2.10.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torch-2.10.0-cp311-cp311-win_amd64.whl.metadata (31 kB)\n",
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/23/19/55b28aecdc7f38df57b8eb55eb0b14a62b470ed8efeb22cdc74224df1d6a/torchvision-0.25.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torchvision-0.25.0-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/69/26/cd2aec609b4f8918e4e85e5c6a3f569bc7b5f72a7ecba3f784077102749c/torchaudio-2.10.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torchaudio-2.10.0-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\arun4\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Obtaining dependency information for typing-extensions>=4.10.0 from https://files.pythonhosted.org/packages/18/67/36e9267722cc04a6b9f15c7f3441c2363321a3ea07da7ae0c0707beb2a9c/typing_extensions-4.15.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Obtaining dependency information for sympy>=1.13.3 from https://files.pythonhosted.org/packages/a2/09/77d55d46fd61b4a135c444fc97158ef34a095e5681d0a6c10b75bf356191/sympy-1.14.0-py3-none-any.whl.metadata\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\arun4\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arun4\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\arun4\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\arun4\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\arun4\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\arun4\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arun4\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Downloading torch-2.10.0-cp311-cp311-win_amd64.whl (113.7 MB)\n",
      "   ---------------------------------------- 0.0/113.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/113.7 MB 1.3 MB/s eta 0:01:29\n",
      "   ---------------------------------------- 0.1/113.7 MB 1.4 MB/s eta 0:01:19\n",
      "   ---------------------------------------- 0.2/113.7 MB 1.3 MB/s eta 0:01:27\n",
      "   ---------------------------------------- 0.2/113.7 MB 1.4 MB/s eta 0:01:19\n",
      "   ---------------------------------------- 0.3/113.7 MB 1.5 MB/s eta 0:01:18\n",
      "   ---------------------------------------- 0.4/113.7 MB 1.6 MB/s eta 0:01:11\n",
      "   ---------------------------------------- 0.5/113.7 MB 1.5 MB/s eta 0:01:16\n",
      "   ---------------------------------------- 0.5/113.7 MB 1.5 MB/s eta 0:01:15\n",
      "   ---------------------------------------- 0.6/113.7 MB 1.5 MB/s eta 0:01:14\n",
      "   ---------------------------------------- 0.7/113.7 MB 1.5 MB/s eta 0:01:14\n",
      "   ---------------------------------------- 0.9/113.7 MB 1.7 MB/s eta 0:01:07\n",
      "   ---------------------------------------- 1.0/113.7 MB 1.8 MB/s eta 0:01:04\n",
      "   ---------------------------------------- 1.0/113.7 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------------------- 1.1/113.7 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------------------- 1.1/113.7 MB 1.6 MB/s eta 0:01:09\n",
      "   ---------------------------------------- 1.1/113.7 MB 1.6 MB/s eta 0:01:09\n",
      "   ---------------------------------------- 1.1/113.7 MB 1.5 MB/s eta 0:01:18\n",
      "   ---------------------------------------- 1.3/113.7 MB 1.6 MB/s eta 0:01:11\n",
      "   ---------------------------------------- 1.3/113.7 MB 1.5 MB/s eta 0:01:16\n",
      "   ---------------------------------------- 1.3/113.7 MB 1.5 MB/s eta 0:01:16\n",
      "   ---------------------------------------- 1.3/113.7 MB 1.5 MB/s eta 0:01:16\n",
      "   ---------------------------------------- 1.3/113.7 MB 1.4 MB/s eta 0:01:23\n",
      "   ---------------------------------------- 1.4/113.7 MB 1.3 MB/s eta 0:01:27\n",
      "   ---------------------------------------- 1.4/113.7 MB 1.3 MB/s eta 0:01:29\n",
      "   ---------------------------------------- 1.4/113.7 MB 1.3 MB/s eta 0:01:29\n",
      "   ---------------------------------------- 1.4/113.7 MB 1.3 MB/s eta 0:01:29\n",
      "    --------------------------------------- 1.6/113.7 MB 1.3 MB/s eta 0:01:27\n",
      "    --------------------------------------- 1.7/113.7 MB 1.3 MB/s eta 0:01:26\n",
      "    --------------------------------------- 1.8/113.7 MB 1.3 MB/s eta 0:01:24\n",
      "    --------------------------------------- 1.8/113.7 MB 1.3 MB/s eta 0:01:24\n",
      "    --------------------------------------- 1.9/113.7 MB 1.4 MB/s eta 0:01:23\n",
      "    --------------------------------------- 2.0/113.7 MB 1.3 MB/s eta 0:01:24\n",
      "    --------------------------------------- 2.1/113.7 MB 1.4 MB/s eta 0:01:22\n",
      "    --------------------------------------- 2.2/113.7 MB 1.4 MB/s eta 0:01:22\n",
      "    --------------------------------------- 2.2/113.7 MB 1.4 MB/s eta 0:01:22\n",
      "    --------------------------------------- 2.3/113.7 MB 1.4 MB/s eta 0:01:22\n",
      "    --------------------------------------- 2.3/113.7 MB 1.4 MB/s eta 0:01:22\n",
      "    --------------------------------------- 2.4/113.7 MB 1.4 MB/s eta 0:01:23\n",
      "    --------------------------------------- 2.5/113.7 MB 1.4 MB/s eta 0:01:22\n",
      "    --------------------------------------- 2.5/113.7 MB 1.4 MB/s eta 0:01:21\n",
      "    --------------------------------------- 2.6/113.7 MB 1.4 MB/s eta 0:01:22\n",
      "    --------------------------------------- 2.6/113.7 MB 1.4 MB/s eta 0:01:22\n",
      "    --------------------------------------- 2.7/113.7 MB 1.4 MB/s eta 0:01:23\n",
      "    --------------------------------------- 2.7/113.7 MB 1.4 MB/s eta 0:01:23\n",
      "    --------------------------------------- 2.8/113.7 MB 1.3 MB/s eta 0:01:25\n",
      "    --------------------------------------- 2.8/113.7 MB 1.3 MB/s eta 0:01:25\n",
      "   - -------------------------------------- 2.8/113.7 MB 1.3 MB/s eta 0:01:25\n",
      "   - -------------------------------------- 2.9/113.7 MB 1.3 MB/s eta 0:01:26\n",
      "   - -------------------------------------- 2.9/113.7 MB 1.3 MB/s eta 0:01:26\n",
      "   - -------------------------------------- 3.0/113.7 MB 1.3 MB/s eta 0:01:26\n",
      "   - -------------------------------------- 3.1/113.7 MB 1.3 MB/s eta 0:01:25\n",
      "   - -------------------------------------- 3.2/113.7 MB 1.3 MB/s eta 0:01:25\n",
      "   - -------------------------------------- 3.3/113.7 MB 1.3 MB/s eta 0:01:24\n",
      "   - -------------------------------------- 3.3/113.7 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 3.4/113.7 MB 1.3 MB/s eta 0:01:24\n",
      "   - -------------------------------------- 3.4/113.7 MB 1.3 MB/s eta 0:01:24\n",
      "   - -------------------------------------- 3.4/113.7 MB 1.3 MB/s eta 0:01:24\n",
      "   - -------------------------------------- 3.5/113.7 MB 1.3 MB/s eta 0:01:25\n",
      "   - -------------------------------------- 3.6/113.7 MB 1.3 MB/s eta 0:01:25\n",
      "   - -------------------------------------- 3.6/113.7 MB 1.3 MB/s eta 0:01:25\n",
      "   - -------------------------------------- 3.7/113.7 MB 1.3 MB/s eta 0:01:25\n",
      "   - -------------------------------------- 3.8/113.7 MB 1.3 MB/s eta 0:01:24\n",
      "   - -------------------------------------- 3.8/113.7 MB 1.3 MB/s eta 0:01:24\n",
      "   - -------------------------------------- 3.9/113.7 MB 1.3 MB/s eta 0:01:24\n",
      "   - -------------------------------------- 4.0/113.7 MB 1.3 MB/s eta 0:01:24\n",
      "   - -------------------------------------- 4.1/113.7 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 4.1/113.7 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 4.2/113.7 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 4.3/113.7 MB 1.3 MB/s eta 0:01:22\n",
      "   - -------------------------------------- 4.4/113.7 MB 1.3 MB/s eta 0:01:22\n",
      "   - -------------------------------------- 4.4/113.7 MB 1.3 MB/s eta 0:01:22\n",
      "   - -------------------------------------- 4.4/113.7 MB 1.3 MB/s eta 0:01:22\n",
      "   - -------------------------------------- 4.4/113.7 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 4.6/113.7 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 4.6/113.7 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 4.7/113.7 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 4.7/113.7 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 4.8/113.7 MB 1.3 MB/s eta 0:01:22\n",
      "   - -------------------------------------- 4.9/113.7 MB 1.3 MB/s eta 0:01:22\n",
      "   - -------------------------------------- 5.0/113.7 MB 1.4 MB/s eta 0:01:21\n",
      "   - -------------------------------------- 5.2/113.7 MB 1.4 MB/s eta 0:01:20\n",
      "   - -------------------------------------- 5.2/113.7 MB 1.4 MB/s eta 0:01:20\n",
      "   - -------------------------------------- 5.3/113.7 MB 1.4 MB/s eta 0:01:19\n",
      "   - -------------------------------------- 5.4/113.7 MB 1.4 MB/s eta 0:01:19\n",
      "   - -------------------------------------- 5.4/113.7 MB 1.4 MB/s eta 0:01:19\n",
      "   - -------------------------------------- 5.5/113.7 MB 1.4 MB/s eta 0:01:19\n",
      "   - -------------------------------------- 5.6/113.7 MB 1.4 MB/s eta 0:01:19\n",
      "   - -------------------------------------- 5.7/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 5.7/113.7 MB 1.4 MB/s eta 0:01:19\n",
      "   -- ------------------------------------- 5.8/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 5.8/113.7 MB 1.4 MB/s eta 0:01:19\n",
      "   -- ------------------------------------- 5.9/113.7 MB 1.4 MB/s eta 0:01:19\n",
      "   -- ------------------------------------- 6.0/113.7 MB 1.4 MB/s eta 0:01:19\n",
      "   -- ------------------------------------- 6.0/113.7 MB 1.4 MB/s eta 0:01:19\n",
      "   -- ------------------------------------- 6.1/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 6.2/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 6.2/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 6.3/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 6.3/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 6.4/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 6.5/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 6.5/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 6.6/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 6.7/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 6.8/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 6.8/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 6.9/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.0/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.0/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.0/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.1/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.2/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.2/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.3/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.4/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.4/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.5/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.6/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.6/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.7/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.7/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.8/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.9/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 7.9/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 8.0/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   -- ------------------------------------- 8.0/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   -- ------------------------------------- 8.1/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 8.1/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 8.2/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 8.2/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 8.3/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 8.4/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 8.4/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   -- ------------------------------------- 8.4/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   --- ------------------------------------ 8.6/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 8.7/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 8.8/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 8.8/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 8.9/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 8.9/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.0/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.1/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.1/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.2/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.2/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.3/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.3/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.4/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.5/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.5/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.6/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.6/113.7 MB 1.4 MB/s eta 0:01:18\n",
      "   --- ------------------------------------ 9.6/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.6/113.7 MB 1.4 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 9.7/113.7 MB 1.3 MB/s eta 0:01:18\n",
      "   --- ------------------------------------ 9.7/113.7 MB 1.3 MB/s eta 0:01:18\n",
      "   --- ------------------------------------ 9.8/113.7 MB 1.3 MB/s eta 0:01:18\n",
      "   --- ------------------------------------ 9.8/113.7 MB 1.3 MB/s eta 0:01:18\n",
      "   --- ------------------------------------ 9.9/113.7 MB 1.3 MB/s eta 0:01:19\n",
      "   --- ------------------------------------ 9.9/113.7 MB 1.3 MB/s eta 0:01:19\n",
      "   --- ------------------------------------ 9.9/113.7 MB 1.3 MB/s eta 0:01:19\n",
      "   --- ------------------------------------ 10.0/113.7 MB 1.3 MB/s eta 0:01:19\n",
      "   --- ------------------------------------ 10.0/113.7 MB 1.3 MB/s eta 0:01:19\n",
      "   --- ------------------------------------ 10.1/113.7 MB 1.3 MB/s eta 0:01:19\n",
      "   --- ------------------------------------ 10.1/113.7 MB 1.3 MB/s eta 0:01:19\n",
      "   --- ------------------------------------ 10.3/113.7 MB 1.3 MB/s eta 0:01:19\n",
      "   --- ------------------------------------ 10.3/113.7 MB 1.3 MB/s eta 0:01:19\n",
      "   --- ------------------------------------ 10.5/113.7 MB 1.3 MB/s eta 0:01:18\n",
      "   --- ------------------------------------ 10.7/113.7 MB 1.3 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 10.9/113.7 MB 1.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 11.1/113.7 MB 1.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 11.2/113.7 MB 1.4 MB/s eta 0:01:15\n",
      "   --- ------------------------------------ 11.3/113.7 MB 1.4 MB/s eta 0:01:15\n",
      "   ---- ----------------------------------- 11.4/113.7 MB 1.4 MB/s eta 0:01:14\n",
      "   ---- ----------------------------------- 11.5/113.7 MB 1.4 MB/s eta 0:01:13\n",
      "   ---- ----------------------------------- 11.5/113.7 MB 1.4 MB/s eta 0:01:13\n",
      "   ---- ----------------------------------- 11.7/113.7 MB 1.5 MB/s eta 0:01:11\n",
      "   ---- ----------------------------------- 11.9/113.7 MB 1.5 MB/s eta 0:01:10\n",
      "   ---- ----------------------------------- 12.0/113.7 MB 1.5 MB/s eta 0:01:10\n",
      "   ---- ----------------------------------- 12.2/113.7 MB 1.5 MB/s eta 0:01:09\n",
      "   ---- ----------------------------------- 12.4/113.7 MB 1.5 MB/s eta 0:01:08\n",
      "   ---- ----------------------------------- 12.6/113.7 MB 1.5 MB/s eta 0:01:08\n",
      "   ---- ----------------------------------- 12.8/113.7 MB 1.5 MB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 12.9/113.7 MB 1.6 MB/s eta 0:01:05\n",
      "   ---- ----------------------------------- 13.1/113.7 MB 1.6 MB/s eta 0:01:04\n",
      "   ---- ----------------------------------- 13.3/113.7 MB 1.6 MB/s eta 0:01:03\n",
      "   ---- ----------------------------------- 13.5/113.7 MB 1.6 MB/s eta 0:01:02\n",
      "   ---- ----------------------------------- 13.6/113.7 MB 1.6 MB/s eta 0:01:01\n",
      "   ---- ----------------------------------- 13.8/113.7 MB 1.7 MB/s eta 0:01:00\n",
      "   ---- ----------------------------------- 13.8/113.7 MB 1.7 MB/s eta 0:01:00\n",
      "   ---- ----------------------------------- 13.9/113.7 MB 1.7 MB/s eta 0:01:00\n",
      "   ---- ----------------------------------- 14.0/113.7 MB 1.7 MB/s eta 0:01:00\n",
      "   ---- ----------------------------------- 14.2/113.7 MB 1.7 MB/s eta 0:00:59\n",
      "   ----- ---------------------------------- 14.4/113.7 MB 1.7 MB/s eta 0:00:58\n",
      "   ----- ---------------------------------- 14.4/113.7 MB 1.7 MB/s eta 0:00:58\n",
      "   ----- ---------------------------------- 14.4/113.7 MB 1.7 MB/s eta 0:00:58\n",
      "   ----- ---------------------------------- 14.6/113.7 MB 1.7 MB/s eta 0:00:58\n",
      "   ----- ---------------------------------- 14.6/113.7 MB 1.7 MB/s eta 0:00:58\n",
      "   ----- ---------------------------------- 14.8/113.7 MB 1.7 MB/s eta 0:00:57\n",
      "   ----- ---------------------------------- 14.9/113.7 MB 1.8 MB/s eta 0:00:57\n",
      "   ----- ---------------------------------- 15.1/113.7 MB 1.8 MB/s eta 0:00:56\n",
      "   ----- ---------------------------------- 15.3/113.7 MB 1.8 MB/s eta 0:00:55\n",
      "   ----- ---------------------------------- 15.6/113.7 MB 1.8 MB/s eta 0:00:54\n",
      "   ----- ---------------------------------- 15.7/113.7 MB 1.8 MB/s eta 0:00:53\n",
      "   ----- ---------------------------------- 15.8/113.7 MB 1.9 MB/s eta 0:00:53\n",
      "   ----- ---------------------------------- 16.1/113.7 MB 1.9 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 16.3/113.7 MB 1.9 MB/s eta 0:00:51\n",
      "   ----- ---------------------------------- 16.4/113.7 MB 1.9 MB/s eta 0:00:50\n",
      "   ----- ---------------------------------- 16.7/113.7 MB 2.0 MB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 16.8/113.7 MB 2.1 MB/s eta 0:00:48\n",
      "   ------ --------------------------------- 17.1/113.7 MB 2.1 MB/s eta 0:00:47\n",
      "   ------ --------------------------------- 17.3/113.7 MB 2.2 MB/s eta 0:00:45\n",
      "   ------ --------------------------------- 17.5/113.7 MB 2.2 MB/s eta 0:00:44\n",
      "   ------ --------------------------------- 17.6/113.7 MB 2.2 MB/s eta 0:00:44\n",
      "   ------ --------------------------------- 17.8/113.7 MB 2.2 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 17.9/113.7 MB 2.3 MB/s eta 0:00:42\n",
      "   ------ --------------------------------- 18.0/113.7 MB 2.3 MB/s eta 0:00:42\n",
      "   ------ --------------------------------- 18.2/113.7 MB 2.3 MB/s eta 0:00:41\n",
      "   ------ --------------------------------- 18.3/113.7 MB 2.4 MB/s eta 0:00:41\n",
      "   ------ --------------------------------- 18.4/113.7 MB 2.4 MB/s eta 0:00:40\n",
      "   ------ --------------------------------- 18.7/113.7 MB 2.5 MB/s eta 0:00:38\n",
      "   ------ --------------------------------- 18.9/113.7 MB 2.5 MB/s eta 0:00:38\n",
      "   ------ --------------------------------- 19.1/113.7 MB 2.6 MB/s eta 0:00:37\n",
      "   ------ --------------------------------- 19.3/113.7 MB 2.7 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 19.6/113.7 MB 2.8 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 19.6/113.7 MB 2.8 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 19.8/113.7 MB 2.9 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 19.9/113.7 MB 3.0 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 20.1/113.7 MB 3.1 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 20.3/113.7 MB 3.4 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 20.6/113.7 MB 3.4 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 20.7/113.7 MB 3.4 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 21.0/113.7 MB 3.4 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 21.2/113.7 MB 3.5 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 21.5/113.7 MB 3.5 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 21.5/113.7 MB 3.5 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 21.5/113.7 MB 3.4 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 21.6/113.7 MB 3.4 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 21.7/113.7 MB 3.4 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 21.9/113.7 MB 3.4 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 21.9/113.7 MB 3.4 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 22.2/113.7 MB 3.4 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 22.4/113.7 MB 3.4 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 22.6/113.7 MB 3.5 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 22.9/113.7 MB 3.5 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 23.0/113.7 MB 3.5 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 23.0/113.7 MB 3.4 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 23.3/113.7 MB 3.5 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 23.4/113.7 MB 3.5 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 23.7/113.7 MB 3.5 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 24.0/113.7 MB 3.5 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 24.1/113.7 MB 3.6 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 24.4/113.7 MB 3.7 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 24.5/113.7 MB 3.6 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 24.8/113.7 MB 3.8 MB/s eta 0:00:24\n",
      "   -------- ------------------------------- 25.0/113.7 MB 3.9 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 25.0/113.7 MB 3.9 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 25.2/113.7 MB 3.8 MB/s eta 0:00:24\n",
      "   -------- ------------------------------- 25.3/113.7 MB 3.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 25.6/113.7 MB 3.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 25.7/113.7 MB 3.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 26.0/113.7 MB 3.8 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 26.1/113.7 MB 3.9 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 26.1/113.7 MB 3.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 26.1/113.7 MB 3.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 26.4/113.7 MB 3.7 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 26.4/113.7 MB 3.7 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 26.6/113.7 MB 3.6 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 26.7/113.7 MB 3.7 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 27.0/113.7 MB 3.7 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 27.2/113.7 MB 3.7 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 27.5/113.7 MB 3.7 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 27.8/113.7 MB 3.7 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 28.0/113.7 MB 3.7 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 28.0/113.7 MB 3.7 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 28.3/113.7 MB 3.7 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 28.4/113.7 MB 3.8 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 28.7/113.7 MB 3.8 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 28.8/113.7 MB 3.8 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 29.0/113.7 MB 3.7 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 29.2/113.7 MB 3.7 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 29.2/113.7 MB 3.7 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 29.6/113.7 MB 3.7 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 29.8/113.7 MB 3.8 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 30.2/113.7 MB 3.9 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 30.5/113.7 MB 3.9 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 30.9/113.7 MB 4.0 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 30.9/113.7 MB 3.9 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 31.3/113.7 MB 4.0 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 31.5/113.7 MB 4.0 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 31.5/113.7 MB 4.0 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 31.6/113.7 MB 3.8 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 32.0/113.7 MB 4.1 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 32.2/113.7 MB 4.2 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 32.5/113.7 MB 4.2 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 32.9/113.7 MB 4.3 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 33.4/113.7 MB 4.5 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 33.5/113.7 MB 4.5 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 33.6/113.7 MB 4.4 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 34.1/113.7 MB 4.5 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 34.3/113.7 MB 4.5 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 34.9/113.7 MB 4.7 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 35.2/113.7 MB 4.6 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 35.5/113.7 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 35.8/113.7 MB 4.9 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 36.2/113.7 MB 5.0 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 36.7/113.7 MB 5.6 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 37.0/113.7 MB 5.7 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 37.1/113.7 MB 5.5 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 37.6/113.7 MB 5.7 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 38.0/113.7 MB 5.7 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 38.4/113.7 MB 6.0 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 38.9/113.7 MB 6.2 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 39.3/113.7 MB 6.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 39.8/113.7 MB 6.9 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 40.0/113.7 MB 6.9 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 40.2/113.7 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 40.5/113.7 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 40.5/113.7 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 40.7/113.7 MB 6.4 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 41.1/113.7 MB 6.4 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 41.2/113.7 MB 6.6 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 41.5/113.7 MB 6.4 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 41.8/113.7 MB 7.0 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 42.0/113.7 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 42.3/113.7 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 42.3/113.7 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 42.3/113.7 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 42.5/113.7 MB 6.5 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 42.8/113.7 MB 6.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 43.5/113.7 MB 6.4 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 44.0/113.7 MB 6.7 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 44.6/113.7 MB 6.9 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 45.1/113.7 MB 6.8 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 45.7/113.7 MB 7.0 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 46.2/113.7 MB 7.2 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 46.9/113.7 MB 7.3 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 47.4/113.7 MB 7.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 47.9/113.7 MB 7.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 48.3/113.7 MB 7.6 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 48.7/113.7 MB 7.6 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 49.3/113.7 MB 7.6 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 49.8/113.7 MB 7.7 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 50.4/113.7 MB 8.2 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 51.0/113.7 MB 9.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 51.1/113.7 MB 8.8 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 51.2/113.7 MB 8.3 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 51.8/113.7 MB 8.8 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 52.1/113.7 MB 9.1 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 52.7/113.7 MB 10.6 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 53.3/113.7 MB 10.7 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 53.5/113.7 MB 10.6 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 54.0/113.7 MB 10.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 54.5/113.7 MB 10.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 55.1/113.7 MB 10.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 55.5/113.7 MB 10.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 56.0/113.7 MB 10.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 56.5/113.7 MB 10.1 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 57.2/113.7 MB 10.1 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 57.7/113.7 MB 10.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 58.2/113.7 MB 10.1 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 58.7/113.7 MB 10.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 59.3/113.7 MB 10.2 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 59.9/113.7 MB 10.4 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 60.4/113.7 MB 10.2 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 61.0/113.7 MB 10.2 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 61.5/113.7 MB 11.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 62.2/113.7 MB 11.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 62.7/113.7 MB 11.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 63.3/113.7 MB 11.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 63.8/113.7 MB 11.9 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 64.4/113.7 MB 11.9 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 64.9/113.7 MB 11.9 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 65.0/113.7 MB 11.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 65.3/113.7 MB 11.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 65.8/113.7 MB 11.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 66.4/113.7 MB 11.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 66.9/113.7 MB 11.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 67.4/113.7 MB 10.9 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 67.9/113.7 MB 10.9 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 68.6/113.7 MB 11.1 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 69.1/113.7 MB 11.1 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 69.6/113.7 MB 11.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 70.2/113.7 MB 10.9 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 70.7/113.7 MB 10.9 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 71.4/113.7 MB 11.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 71.9/113.7 MB 11.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 72.5/113.7 MB 11.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 72.9/113.7 MB 10.9 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 73.5/113.7 MB 10.9 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 73.7/113.7 MB 10.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 73.9/113.7 MB 10.2 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 74.4/113.7 MB 10.2 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 74.9/113.7 MB 10.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 75.5/113.7 MB 10.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 75.9/113.7 MB 10.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 76.3/113.7 MB 10.7 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 76.8/113.7 MB 10.7 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 77.3/113.7 MB 10.7 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 77.8/113.7 MB 10.7 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 78.2/113.7 MB 10.7 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 78.3/113.7 MB 10.4 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 78.7/113.7 MB 9.9 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 79.2/113.7 MB 9.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 79.7/113.7 MB 9.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 80.3/113.7 MB 9.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 80.8/113.7 MB 9.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 81.4/113.7 MB 9.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 82.0/113.7 MB 9.9 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 82.6/113.7 MB 10.1 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 83.1/113.7 MB 10.1 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 83.5/113.7 MB 9.9 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 84.1/113.7 MB 10.4 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 84.7/113.7 MB 10.6 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 85.2/113.7 MB 10.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 85.8/113.7 MB 10.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 86.4/113.7 MB 10.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 86.9/113.7 MB 10.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 87.5/113.7 MB 10.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 88.0/113.7 MB 10.9 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 88.5/113.7 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 89.1/113.7 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 89.7/113.7 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 90.2/113.7 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 90.8/113.7 MB 11.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 91.3/113.7 MB 11.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 91.7/113.7 MB 11.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 92.3/113.7 MB 11.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 92.8/113.7 MB 11.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 93.5/113.7 MB 11.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 94.0/113.7 MB 11.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 94.6/113.7 MB 11.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 95.2/113.7 MB 11.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 95.8/113.7 MB 11.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 96.3/113.7 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 96.9/113.7 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 97.5/113.7 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 98.0/113.7 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 98.7/113.7 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 99.2/113.7 MB 12.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 99.8/113.7 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 100.3/113.7 MB 12.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 100.8/113.7 MB 12.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 101.2/113.7 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 101.9/113.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 102.5/113.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 103.1/113.7 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 103.6/113.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 104.2/113.7 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 104.7/113.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 105.4/113.7 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 106.0/113.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 106.5/113.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 107.1/113.7 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 107.6/113.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 108.2/113.7 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 108.7/113.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 108.9/113.7 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 109.1/113.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 109.8/113.7 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 110.3/113.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 110.8/113.7 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  111.3/113.7 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  111.9/113.7 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  112.4/113.7 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  112.9/113.7 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.5/113.7 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.7/113.7 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.7/113.7 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.7/113.7 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.7/113.7 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.7/113.7 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 113.7/113.7 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.25.0-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/4.0 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.4/4.0 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 8.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.5/4.0 MB 8.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.1/4.0 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.6/4.0 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.2/4.0 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.9/4.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 9.9 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.10.0-cp311-cp311-win_amd64.whl (474 kB)\n",
      "   ---------------------------------------- 0.0/474.8 kB ? eta -:--:--\n",
      "   --------------------------------------  471.0/474.8 kB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 474.8/474.8 kB 9.9 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/6.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.1/6.3 MB 11.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.5/6.3 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.8/6.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.3 MB 9.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.4/6.3 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.1/6.3 MB 9.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.6/6.3 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.3 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.4/6.3 MB 10.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.9/6.3 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 10.1 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: typing-extensions, sympy, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.11.1\n",
      "    Uninstalling sympy-1.11.1:\n",
      "      Successfully uninstalled sympy-1.11.1\n",
      "Successfully installed sympy-1.14.0 torch-2.10.0 torchaudio-2.10.0 torchvision-0.25.0 typing-extensions-4.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f5b35da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.46.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f6ad16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51de3df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17399926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "binary_path: c:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
      "CUDA SETUP: Loading binary c:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n",
      "Could not find module 'c:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "CUDA SETUP: Loading binary c:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n",
      "Could not find module 'c:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "CUDA SETUP: Loading binary c:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n",
      "Could not find module 'c:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA library was not detected.\n",
      "CUDA SETUP: Solution 1): Your paths are probably not up-to-date. You can update them via: sudo ldconfig.\n",
      "CUDA SETUP: Solution 2): If you do not have sudo rights, you can do the following:\n",
      "CUDA SETUP: Solution 2a): Find the cuda library via: find / -name libcuda.so 2>/dev/null\n",
      "CUDA SETUP: Solution 2b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_2a\n",
      "CUDA SETUP: Solution 2c): For a permanent solution add the export from 2b into your .bashrc file, located at ~/.bashrc\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n        CUDA Setup failed despite GPU being available. Inspect the CUDA SETUP outputs above to fix your environment!\n        If you cannot find any issues and suspect a bug, please open an issue with detals about your environment:\n        https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbitsandbytes\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(bitsandbytes.__version__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\bitsandbytes\\__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cuda_setup, utils\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograd\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     MatmulLtState,\n\u001b[32m      9\u001b[39m     bmm_cublas,\n\u001b[32m     10\u001b[39m     matmul,\n\u001b[32m     11\u001b[39m     matmul_cublas,\n\u001b[32m     12\u001b[39m     mm_cublas,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m modules\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\bitsandbytes\\autograd\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m undo_layout, get_inverse_transform_indices\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tuple, Optional\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbitsandbytes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# math.prod not compatible with python < 3.8\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprod\u001b[39m(iterable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\bitsandbytes\\functional.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tuple\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA, lib\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# math.prod not compatible with python < 3.8\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprod\u001b[39m(iterable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\bitsandbytes\\cextension.py:22\u001b[39m\n\u001b[32m     20\u001b[39m     CUDASetup.get_instance().generate_instructions()\n\u001b[32m     21\u001b[39m     CUDASetup.get_instance().print_log_stack()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'''\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m    CUDA Setup failed despite GPU being available. Inspect the CUDA SETUP outputs above to fix your environment!\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m    If you cannot find any issues and suspect a bug, please open an issue with detals about your environment:\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[33m    https://github.com/TimDettmers/bitsandbytes/issues\u001b[39m\u001b[33m'''\u001b[39m)\n\u001b[32m     26\u001b[39m lib.cadam32bit_g32\n\u001b[32m     27\u001b[39m lib.get_context.restype = ct.c_void_p\n",
      "\u001b[31mRuntimeError\u001b[39m: \n        CUDA Setup failed despite GPU being available. Inspect the CUDA SETUP outputs above to fix your environment!\n        If you cannot find any issues and suspect a bug, please open an issue with detals about your environment:\n        https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "import bitsandbytes\n",
    "print(bitsandbytes.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe7def4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 2.5.1+cu121\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c85c771",
   "metadata": {},
   "source": [
    "Loading the model --->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729d13a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "PackageNotFoundError",
     "evalue": "No package metadata was found for bitsandbytes",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mStopIteration\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\metadata\\__init__.py:563\u001b[39m, in \u001b[36mDistribution.from_name\u001b[39m\u001b[34m(cls, name)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mcls\u001b[39m.discover(name=name))\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[31mStopIteration\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mPackageNotFoundError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m tokenizer.pad_token = tokenizer.eos_token\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 4-bit quantization config (ideal for RTX 4050 6GB)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m bnb_config = \u001b[43mBitsAndBytesConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbnb_4bit_compute_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat16\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Load model on GPU\u001b[39;00m\n\u001b[32m     17\u001b[39m model = AutoModelForCausalLM.from_pretrained(\n\u001b[32m     18\u001b[39m     model_name,\n\u001b[32m     19\u001b[39m     quantization_config=bnb_config,\n\u001b[32m     20\u001b[39m     device_map=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     21\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\transformers\\utils\\quantization_config.py:417\u001b[39m, in \u001b[36mBitsAndBytesConfig.__init__\u001b[39m\u001b[34m(self, load_in_8bit, load_in_4bit, llm_int8_threshold, llm_int8_skip_modules, llm_int8_enable_fp32_cpu_offload, llm_int8_has_fp16_weight, bnb_4bit_compute_dtype, bnb_4bit_quant_type, bnb_4bit_use_double_quant, bnb_4bit_quant_storage, **kwargs)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[32m    415\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnused kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. These kwargs are not used in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpost_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arun4\\OneDrive\\Desktop\\LLM\\venv\\Lib\\site-packages\\transformers\\utils\\quantization_config.py:475\u001b[39m, in \u001b[36mBitsAndBytesConfig.post_init\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.bnb_4bit_use_double_quant, \u001b[38;5;28mbool\u001b[39m):\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mbnb_4bit_use_double_quant must be a boolean\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.load_in_4bit \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m version.parse(\u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbitsandbytes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m) >= version.parse(\n\u001b[32m    476\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m0.39.0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m ):\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    479\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m4 bit quantization requires bitsandbytes>=0.39.0 - please upgrade your bitsandbytes version\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    480\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\metadata\\__init__.py:1009\u001b[39m, in \u001b[36mversion\u001b[39m\u001b[34m(distribution_name)\u001b[39m\n\u001b[32m   1002\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mversion\u001b[39m(distribution_name):\n\u001b[32m   1003\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the version string for the named package.\u001b[39;00m\n\u001b[32m   1004\u001b[39m \n\u001b[32m   1005\u001b[39m \u001b[33;03m    :param distribution_name: The name of the distribution package to query.\u001b[39;00m\n\u001b[32m   1006\u001b[39m \u001b[33;03m    :return: The version string for the package as defined in the package's\u001b[39;00m\n\u001b[32m   1007\u001b[39m \u001b[33;03m        \"Version\" metadata key.\u001b[39;00m\n\u001b[32m   1008\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1009\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m.version\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\metadata\\__init__.py:982\u001b[39m, in \u001b[36mdistribution\u001b[39m\u001b[34m(distribution_name)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdistribution\u001b[39m(distribution_name):\n\u001b[32m    977\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the ``Distribution`` instance for the named package.\u001b[39;00m\n\u001b[32m    978\u001b[39m \n\u001b[32m    979\u001b[39m \u001b[33;03m    :param distribution_name: The name of the distribution package as a string.\u001b[39;00m\n\u001b[32m    980\u001b[39m \u001b[33;03m    :return: A ``Distribution`` instance (or subclass thereof).\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDistribution\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\metadata\\__init__.py:565\u001b[39m, in \u001b[36mDistribution.from_name\u001b[39m\u001b[34m(cls, name)\u001b[39m\n\u001b[32m    563\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mcls\u001b[39m.discover(name=name))\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(name)\n",
      "\u001b[31mPackageNotFoundError\u001b[39m: No package metadata was found for bitsandbytes"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-3B\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 4-bit quantization config (ideal for RTX 4050 6GB)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load model on GPU\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"Model successfully loaded on RTX 4050!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f9265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4cae96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e623358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37402a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1823a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6bf714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149ec1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a6e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
